# -*- coding: utf-8 -*-
"""Tentativa com mais features LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZRKqFndoVtKnpBgHRGt4miYoYjkBXqXQ
"""

import numpy as np
import pandas_datareader as web
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import math
from matplotlib.pyplot import figure
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout

df = web.DataReader("PETR4.SA", data_source="yahoo", start="2015-01-01", end="2019-12-31")
df

df.shape

df_bovespa = web.DataReader("^BVSP", data_source="yahoo", start="2015-01-01", end="2019-12-31")
# df_bovespa.reset_index(inplace=True,drop=False)
df_bovespa

df_bovespa.shape

df = df.merge(df_bovespa, left_on='Date', right_on='Date', suffixes=('', '_bovespa'))
df.describe()

df['MA3'] = df['Close'].rolling(window=3, min_periods=0).mean()
df['MA7'] = df['Close'].rolling(window=7, min_periods=0).mean()
df['MA20'] = df['Close'].rolling(window=20, min_periods=0).mean()
df['MA30'] = df['Close'].rolling(window=30, min_periods=0).mean()
df['MA60'] = df['Close'].rolling(window=60, min_periods=0).mean()

cma3 = df['Close'].expanding(min_periods=3).mean()
df['CMA3'] = cma3.fillna(df['MA3'])

df['ST3'] = df['Close'].rolling(window=3, min_periods=0).std(ddof=0)
df['ST7'] = df['Close'].rolling(window=7, min_periods=0).std(ddof=0)
df['ST20'] = df['Close'].rolling(window=20, min_periods=0).std(ddof=0)
df['ST30'] = df['Close'].rolling(window=30, min_periods=0).std(ddof=0)
df['ST60'] = df['Close'].rolling(window=60, min_periods=0).std(ddof=0)

df['UPPER3'] = df['MA3'] + (df['ST3'] * 2) 
df['LOWER3'] = df['MA3'] - (df['ST3'] * 2)

df['UPPER7'] = df['MA7'] + (df['ST7'] * 2)
df['LOWER7'] = df['MA7'] - (df['ST7'] * 2)

df['UPPER20'] = df['MA20'] + (df['ST20'] * 2)
df['LOWER20'] = df['MA20'] - (df['ST20'] * 2)

df['UPPER30'] = df['MA30'] + (df['ST30'] * 2)
df['LOWER30'] = df['MA30'] - (df['ST30'] * 2)

df['UPPER60'] = df['MA60'] + (df['ST60'] * 2)
df['LOWER60'] = df['MA60'] - (df['ST60'] * 2)

data = df.filter(["Close", 'MA3', 'CMA3', 'LOWER3', 'UPPER3'])
figure(figsize=(20, 6), dpi=80)
plt.plot(df.index, data)
plt.title('Previsão de série temporal')
plt.xlabel('Tempo')
plt.ylabel('Cotação (R$)')
plt.legend()
plt.show()

data = df.filter(["Close", 'MA7', 'LOWER7', 'UPPER7'])
figure(figsize=(20, 6), dpi=80)
plt.plot(df.index, data)
plt.title('Previsão de série temporal')
plt.xlabel('Tempo')
plt.ylabel('Cotação (R$)')
plt.legend()
plt.show()

data = df.filter(["Close", 'MA20', 'LOWER20', 'UPPER20'])
figure(figsize=(20, 6), dpi=80)
plt.plot(df.index, data)
plt.title('Previsão de série temporal')
plt.xlabel('Tempo')
plt.ylabel('Cotação (R$)')
plt.legend()
plt.show()

data = df.filter(["Close", 'MA30', 'LOWER30', 'UPPER30'])
figure(figsize=(20, 6), dpi=80)
plt.plot(df.index, data)
plt.title('Previsão de série temporal')
plt.xlabel('Tempo')
plt.ylabel('Cotação (R$)')
plt.legend()
plt.show()

data = df.filter(["Close", 'MA60', 'LOWER60', 'UPPER60'])
figure(figsize=(20, 6), dpi=80)
plt.plot(df.index, data)
plt.title('Previsão de série temporal')
plt.xlabel('Tempo')
plt.ylabel('Cotação (R$)')
plt.legend()
plt.show()

window_size = 3
N = len(df)
std_avg_predictions_3 = []
std_avg_predictions_7 = []
std_avg_predictions_20 = []
std_avg_predictions_30 = []
std_avg_predictions_60 = []

mse_errors_3 = []
mse_errors_7 = []
mse_errors_20 = []
mse_errors_30 = []
mse_errors_60 = []

dataNoIndex = df.reset_index()

for pred_idx in range(window_size,N):
    std_avg_predictions_3.append(np.mean(dataNoIndex[pred_idx-window_size:pred_idx]['Close']))
    mse_errors_3.append((std_avg_predictions_3[-1] - dataNoIndex[pred_idx:pred_idx + 1]['Close'])**2)

print('MSE error for standard averaging (window 3): %.5f'%(0.5*np.mean(mse_errors_3)))

window_size = 7
for pred_idx in range(window_size,N):
    std_avg_predictions_7.append(np.mean(dataNoIndex[pred_idx-window_size:pred_idx]['Close']))
    mse_errors_7.append((std_avg_predictions_7[-1] - dataNoIndex[pred_idx:pred_idx + 1]['Close'])**2)

print('MSE error for standard averaging (window 7): %.5f'%(0.5*np.mean(mse_errors_7)))

window_size = 20
for pred_idx in range(window_size,N):
    std_avg_predictions_20.append(np.mean(dataNoIndex[pred_idx-window_size:pred_idx]['Close']))
    mse_errors_20.append((std_avg_predictions_20[-1] - dataNoIndex[pred_idx:pred_idx + 1]['Close'])**2)

print('MSE error for standard averaging (window 20): %.5f'%(0.5*np.mean(mse_errors_20)))

window_size = 30
for pred_idx in range(window_size,N):
    std_avg_predictions_30.append(np.mean(dataNoIndex[pred_idx-window_size:pred_idx]['Close']))
    mse_errors_30.append((std_avg_predictions_30[-1] - dataNoIndex[pred_idx:pred_idx + 1]['Close'])**2)

print('MSE error for standard averaging (window 30): %.5f'%(0.5*np.mean(mse_errors_30)))

window_size = 60
for pred_idx in range(window_size,N):
    std_avg_predictions_60.append(np.mean(dataNoIndex[pred_idx-window_size:pred_idx]['Close']))
    mse_errors_60.append((std_avg_predictions_60[-1] - dataNoIndex[pred_idx:pred_idx + 1]['Close'])**2)

print('MSE error for standard averaging (window 60): %.5f'%(0.5*np.mean(mse_errors_60)))

window_size = 60
N = len(dataNoIndex)

run_avg_predictions = []
run_avg_x = []

mse_errors = []

running_mean = 0.0
run_avg_predictions.append(running_mean)

decay = 0.5

for pred_idx in range(1,N):
    running_mean = running_mean * decay + (1.0-decay) * dataNoIndex[pred_idx-1:pred_idx]['Close'].item()
    run_avg_predictions.append(running_mean)
    mse_errors.append((run_avg_predictions[-1] - dataNoIndex[pred_idx:pred_idx + 1]['Close'].item())**2)

print('MSE error for EMA averaging: %.5f'%(0.5*np.mean(mse_errors)))

data = df.filter(["Close", "Volume", "Close_bovespa", "Volume_bovespa", 'MA3', 'MA7', 'MA20', 'MA30', 'MA60', 'CMA3', 'ST3', 'ST7', 'ST20', 'ST30', 'ST60', 'UPPER3', 'LOWER3', 'UPPER7', 'LOWER7', 'UPPER20', 'LOWER20', 'UPPER30', 'LOWER30', 'UPPER60', 'LOWER60'])
dataset = data.values
training_data_len = math.ceil(len(dataset) * .7)
training_data_len
dataset.shape
data

sc = StandardScaler()
scaled_data = sc.fit_transform(dataset)

scaled_data

train_data = scaled_data[0:training_data_len,:]
# print(train_data)
window = 60
X_train = []
y_train = []
for i in range(window, len(train_data)):
    X_train.append(train_data[i-window:i,:])
    y_train.append(train_data[i, 0:1])
    # if i <= (window + 1):
    #   print(X_train)
    #   print(y_train)
    #   print()
X_train, y_train = np.array(X_train), np.array(y_train)

X_train.shape

X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], -1))

X_train.shape

# Inicializar a RNN
regressor = Sequential()

# Adicionar a primeira camada LSTM e Dropout 
regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))
regressor.add(Dropout(0.2))
 
# Adicionar a segunda camada LSTM e Dropout
regressor.add(LSTM(units = 80, return_sequences = True))
regressor.add(Dropout(0.2))
 
# Adicionar a terceira camada LSTM e Dropout
regressor.add(LSTM(units = 50))
regressor.add(Dropout(0.2))
 
# camada de saída
regressor.add(Dense(units = 1))
 
# Compilar a rede
regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')
# regressor.compile(loss = 'mean_squared_error')

# Visualizar a rede
regressor.summary()

history = regressor.fit(X_train, y_train, epochs = 50, batch_size = 1)

plt.plot(history.history['loss'], label='treino')
plt.legend();

test_data = scaled_data[training_data_len - window:, :]

X_test = []
y_test = dataset[training_data_len:, 0:1]

for i in range(window, len(test_data)): 
    X_test.append(test_data[i-window:i,:])
X_test = np.array(X_test)

X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], -1))
print(X_test.shape, X_train.shape)

predicted = regressor.predict(X_test)
volume = dataset[training_data_len:, 1:]
predicted = np.column_stack((predicted, volume))
# print(dataset[:,1:])
print(predicted.shape)
predicted = sc.inverse_transform(predicted)
print(predicted)

allTargetData = np.vstack((dataset[:training_data_len, 0:1], dataset[training_data_len:, 0:1]))
training_predicted = regressor.predict(X_train)
volume = dataset[:len(X_train), 1:]
training_predicted = np.column_stack((training_predicted, volume))
training_predicted = sc.inverse_transform(training_predicted)
allForecastedData = np.vstack((dataset[0:window, 0:1], training_predicted[:,0:1], predicted[:,0:1]))
# date = df['DATA']
date = df.index

figure(figsize=(20, 6), dpi=80)
plt.plot(date, allForecastedData, color = 'red', label = 'Previsto')
plt.plot(date, allTargetData, color = 'blue', label = 'Real')
plt.title('Previsão de série temporal')
plt.xlabel('Tempo')
plt.ylabel('Cotação (R$)')
plt.legend()
plt.show()

rmse = math.sqrt(mean_squared_error(dataset[training_data_len:, 0:1], predicted[:,0:1]))
print('RMSE: ', rmse)

mse = mean_squared_error(dataset[training_data_len:, 0:1], predicted[:,0:1])
print('MSE: ',mse)

mape = np.mean(np.abs((dataset[training_data_len:, 0:1]-predicted[:,0:1]) /dataset[training_data_len:, 0:1])) * 100
print('MAPE: ',mape, '%')

print('R2: ', r2_score(predicted[:,0:1], dataset[training_data_len:, 0:1]))