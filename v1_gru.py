# -*- coding: utf-8 -*-
"""V1 GRU.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tpMf6-1iVxyyJamf0tHDJjTlF9w5NnuZ
"""

import numpy as np
import pandas_datareader as web
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import math
from matplotlib.pyplot import figure
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional
from keras.optimizers import SGD
from datetime import date, datetime, timedelta
plt.style.use('fivethirtyeight')

df = web.DataReader("PETR4.SA", data_source="yahoo", start="2018-01-01", end="2019-12-31")
df

df.shape

df_bovespa = web.DataReader("^BVSP", data_source="yahoo", start="2018-01-01", end="2019-12-31")
# df_bovespa.reset_index(inplace=True,drop=False)
df_bovespa

df_bovespa.shape

df_dolar = web.DataReader("USDBRL=X", data_source="yahoo", start="2018-01-01", end="2019-12-31")
df_dolar

df = df.merge(df_bovespa, left_on='Date', right_on='Date', suffixes=('', '_bovespa'))
df = df.merge(df_dolar, left_on='Date', right_on='Date', suffixes=('', '_dolar'))

df.head()

data = df.filter(["Close", "Volume", "Close_bovespa", "Volume_bovespa", "Close_dolar"])
dataset = data.values
training_data_len = math.ceil(len(dataset) * .7)
training_data_len
dataset.shape

sc = StandardScaler()
sc = sc.fit(dataset)
scaled_data = sc.transform(dataset)

scaled_data

train_data = scaled_data[0:training_data_len,:]
# print(train_data)
window = 60
X_train = []
y_train = []
for i in range(window, len(train_data)):
    X_train.append(train_data[i-window:i,:])
    y_train.append(train_data[i, 0:1])
X_train, y_train = np.array(X_train), np.array(y_train)

X_train.shape

X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], -1))

X_train.shape

units1=50
units2=50
units3=50
units4=50
mybatch = 32
myepochs = 25
unitsoutput = 1

# The GRU architecture
regressor = Sequential()
# First GRU layer with Dropout regularisation
regressor.add(GRU(units=units1, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh'))
regressor.add(Dropout(0.2))
# Second GRU layer
regressor.add(GRU(units=units2, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh'))
regressor.add(Dropout(0.2))
# Third GRU layer
regressor.add(GRU(units=units3, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh'))
regressor.add(Dropout(0.2))
# Fourth GRU layer
regressor.add(GRU(units=units4, activation='tanh'))
regressor.add(Dropout(0.2))
# The output layer
regressor.add(Dense(units=unitsoutput))
# Compiling the RNN
regressor.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')
# Fitting to the training set
regressor.summary()

history = regressor.fit(X_train, y_train, epochs = 25, batch_size = 32)

plt.plot(history.history['loss'], label='treino')
plt.legend();

test_data = scaled_data[training_data_len - window:, :]

X_test = []
y_test = dataset[training_data_len:, 0:1]

for i in range(window, len(test_data)): 
    X_test.append(test_data[i-window:i,:])
X_test = np.array(X_test)

X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], -1))
print(X_test.shape, X_train.shape)

predicted = regressor.predict(X_test)
volume = dataset[training_data_len:, 1:]
predicted = np.column_stack((predicted, volume))
predicted = sc.inverse_transform(predicted)

allTargetData = np.vstack((dataset[:training_data_len, 0:1], dataset[training_data_len:, 0:1]))
training_predicted = regressor.predict(X_train)
volume = dataset[:len(X_train), 1:]
training_predicted = np.column_stack((training_predicted, volume))
training_predicted = sc.inverse_transform(training_predicted)
allForecastedData = np.vstack((dataset[0:window, 0:1], training_predicted[:,0:1], predicted[:,0:1]))
# date = df['DATA']
date = df.index

figure(figsize=(20, 6), dpi=80)
plt.plot(date, allForecastedData, color = 'red', label = 'Previsto')
plt.plot(date, allTargetData, color = 'blue', label = 'Real')
plt.title('Previsão de série temporal')
plt.xlabel('Tempo')
plt.ylabel('Cotação (R$)')
plt.legend()
plt.show()

rmse = math.sqrt(mean_squared_error(dataset[training_data_len:, 0:1], predicted[:,0:1]))
print('RMSE: ', rmse)

mse = mean_squared_error(dataset[training_data_len:, 0:1], predicted[:,0:1])
print('MSE: ',mse)

mape = np.mean(np.abs((dataset[training_data_len:, 0:1]-predicted[:,0:1]) /dataset[training_data_len:, 0:1])) * 100
print('MAPE: ',mape, '%')

print('R2: ', r2_score(predicted[:,0:1], dataset[training_data_len:, 0:1]))

today = datetime.today()
today_minus_100 = today - timedelta(days=100)
df_new = web.DataReader("PETR4.SA", data_source="yahoo", start=today_minus_100, end=today)
df_bovespa_new = web.DataReader("^BVSP", data_source="yahoo", start=today_minus_100, end=today)
df_dolar_new = web.DataReader("USDBRL=X", data_source="yahoo", start=today_minus_100, end=today)
df_new = df_new.merge(df_bovespa_new, left_on='Date', right_on='Date', suffixes=('', '_bovespa'))
df_new = df_new.merge(df_dolar_new, left_on='Date', right_on='Date', suffixes=('', '_dolar'))
df_new = df_new.filter(["Close", "Volume", "Close_bovespa", "Volume_bovespa", "Close_dolar"])


print(df_new.tail())
last_days = df_new.values
scaled = sc.transform(last_days)
x = []
x.append(scaled)
x = np.array(x)
x = np.reshape(x, (x.shape[0], x.shape[1], -1))
pred_price = regressor.predict(x)
volume_new = last_days[0:1, 1:]
pred_price = np.column_stack((pred_price, volume_new))
pred_price = sc.inverse_transform(pred_price)
print(pred_price[0][0])